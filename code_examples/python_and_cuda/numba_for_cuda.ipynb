{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb3991b",
   "metadata": {},
   "source": [
    "# Adding 10 million Vectors with Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1e876a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, cuda\n",
    "import time as time_module\n",
    "\n",
    "# 1. Pure Python version (baseline - slowest)\n",
    "def vector_add_python(a, b, c):\n",
    "    for i in range(len(a)):\n",
    "        c[i] = a[i] + b[i]\n",
    "\n",
    "# 2. Numba CPU version (JIT compiled)\n",
    "@jit(nopython=True)\n",
    "def vector_add_numba_cpu(a, b, c):\n",
    "    for i in range(len(a)):\n",
    "        c[i] = a[i] + b[i]\n",
    "\n",
    "# 3. Numba CUDA version (GPU kernel)\n",
    "@cuda.jit\n",
    "def vector_add_cuda_kernel(a, b, c):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < c.size:\n",
    "        c[idx] = a[idx] + b[idx]\n",
    "\n",
    "def vector_add_cuda(a, b):\n",
    "    d_a = cuda.to_device(a)\n",
    "    d_b = cuda.to_device(b)\n",
    "    d_c = cuda.device_array_like(a)\n",
    "    \n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (a.size + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    vector_add_cuda_kernel[blocks_per_grid, threads_per_block](d_a, d_b, d_c)\n",
    "    \n",
    "    c = d_c.copy_to_host()\n",
    "    return c\n",
    "\n",
    "def vector_add_cuda_no_transfer(d_a, d_b, d_c, threads_per_block, blocks_per_grid):\n",
    "    \"\"\"GPU kernel without memory transfers - data already on GPU\"\"\"\n",
    "    vector_add_cuda_kernel[blocks_per_grid, threads_per_block](d_a, d_b, d_c)\n",
    "    cuda.synchronize()\n",
    "\n",
    "def benchmark(func, *args, warmup=True):\n",
    "    if warmup:\n",
    "        func(*args)\n",
    "    \n",
    "    times = []\n",
    "    for _ in range(5):\n",
    "        start = time_module.perf_counter()\n",
    "        result = func(*args)\n",
    "        end = time_module.perf_counter()\n",
    "        times.append(end - start)\n",
    "    \n",
    "    return np.mean(times), result\n",
    "\n",
    "def check_cuda():\n",
    "    try:\n",
    "        cuda.select_device(0)\n",
    "        cuda.current_context()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def format_time(ms):\n",
    "    \"\"\"Format time with appropriate units\"\"\"\n",
    "    if ms >= 1000:\n",
    "        return f\"{ms/1000:.2f}s\"\n",
    "    elif ms >= 1:\n",
    "        return f\"{ms:.2f}ms\"\n",
    "    else:\n",
    "        return f\"{ms*1000:.2f}μs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75cc99e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vector Addition Benchmark: 10,000,000 elements\n",
      "\n",
      "┌─────────────────────────────┬──────────┬──────────────┬─────────────┐\n",
      "│ Method                      │ Time     │ vs Python    │ vs CPU      │\n",
      "├─────────────────────────────┼──────────┼──────────────┼─────────────┤\n",
      "│ Pure Python                 │ 684.34ms │ 1.0x         │ -           │\n",
      "│ Numba CPU                   │   2.80ms │   245x faster │ -           │\n",
      "│ GPU (with transfer)         │  10.95ms │    63x faster │   0.3x slower │\n",
      "│ GPU (kernel only)           │   0.08ms │  8788x faster │    36x faster │\n",
      "└─────────────────────────────┴──────────┴──────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "N = 10_000_000\n",
    "a = np.random.rand(N).astype(np.float32)\n",
    "b = np.random.rand(N).astype(np.float32)\n",
    "\n",
    "print(f\"\\nVector Addition Benchmark: {N:,} elements\\n\")\n",
    "\n",
    "# Benchmark\n",
    "c_python = np.zeros_like(a)\n",
    "time_python, _ = benchmark(vector_add_python, a, b, c_python, warmup=False)\n",
    "\n",
    "c_cpu = np.zeros_like(a)\n",
    "time_cpu, _ = benchmark(vector_add_numba_cpu, a, b, c_cpu)\n",
    "\n",
    "cuda_available = check_cuda()\n",
    "\n",
    "if cuda_available:\n",
    "    # GPU with transfer\n",
    "    time_gpu, c_gpu = benchmark(vector_add_cuda, a, b)\n",
    "    \n",
    "    # GPU kernel only\n",
    "    d_a = cuda.to_device(a)\n",
    "    d_b = cuda.to_device(b)\n",
    "    d_c = cuda.device_array_like(a)\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (a.size + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    vector_add_cuda_no_transfer(d_a, d_b, d_c, threads_per_block, blocks_per_grid)\n",
    "    times = []\n",
    "    for _ in range(5):\n",
    "        start = time_module.perf_counter()\n",
    "        vector_add_cuda_no_transfer(d_a, d_b, d_c, threads_per_block, blocks_per_grid)\n",
    "        times.append(time_module.perf_counter() - start)\n",
    "    time_kernel = np.mean(times)\n",
    "    \n",
    "    print(\"┌─────────────────────────────┬──────────┬──────────────┬─────────────┐\")\n",
    "    print(\"│ Method                      │ Time     │ vs Python    │ vs CPU      │\")\n",
    "    print(\"├─────────────────────────────┼──────────┼──────────────┼─────────────┤\")\n",
    "    print(f\"│ Pure Python                 │ {format_time(time_python*1000):>8} │ 1.0x         │ -           │\")\n",
    "    print(f\"│ Numba CPU                   │ {format_time(time_cpu*1000):>8} │ {time_python/time_cpu:>5.0f}x faster │ -           │\")\n",
    "    print(f\"│ GPU (with transfer)         │ {format_time(time_gpu*1000):>8} │ {time_python/time_gpu:>5.0f}x faster │ {time_cpu/time_gpu:>5.1f}x slower │\")\n",
    "    \n",
    "    # Format kernel time to show both ms and μs for consistency\n",
    "    kernel_ms = time_kernel * 1000\n",
    "    if kernel_ms < 1:\n",
    "        kernel_display = f\"{kernel_ms:.2f}ms\"\n",
    "    else:\n",
    "        kernel_display = format_time(kernel_ms)\n",
    "    \n",
    "    print(f\"│ GPU (kernel only)           │ {kernel_display:>8} │ {time_python/time_kernel:>5.0f}x faster │ {time_cpu/time_kernel:>5.0f}x faster │\")\n",
    "    print(\"└─────────────────────────────┴──────────┴──────────────┴─────────────┘\")\n",
    "else:\n",
    "    # CPU only table\n",
    "    print(\"┌─────────────────────────────┬──────────┬──────────────┐\")\n",
    "    print(\"│ Method                      │ Time     │ vs Python    │\")\n",
    "    print(\"├─────────────────────────────┼──────────┼──────────────┤\")\n",
    "    print(f\"│ Pure Python                 │ {format_time(time_python*1000):>8} │ 1.0x         │\")\n",
    "    print(f\"│ Numba CPU                   │ {format_time(time_cpu*1000):>8} │ {time_python/time_cpu:>5.0f}x faster │\")\n",
    "    print(\"└─────────────────────────────┴──────────┴──────────────┘\")\n",
    "    print(\"\\n(GPU not available)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71a0f8",
   "metadata": {},
   "source": [
    "# Scaling the operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849a75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, cuda\n",
    "import time as time_module\n",
    "\n",
    "@jit(nopython=True)\n",
    "def vector_add_cpu(a, b, c):\n",
    "    for i in range(len(a)):\n",
    "        c[i] = a[i] + b[i]\n",
    "\n",
    "@cuda.jit\n",
    "def vector_add_gpu_kernel(a, b, c):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < c.size:\n",
    "        c[idx] = a[idx] + b[idx]\n",
    "\n",
    "def benchmark_cpu_n_ops(a, b, n_ops):\n",
    "    \"\"\"Benchmark CPU for n operations\"\"\"\n",
    "    c = np.zeros_like(a)\n",
    "    \n",
    "    # Warmup\n",
    "    vector_add_cpu(a, b, c)\n",
    "    \n",
    "    # Measure\n",
    "    start = time_module.perf_counter()\n",
    "    for _ in range(n_ops):\n",
    "        vector_add_cpu(a, b, c)\n",
    "    end = time_module.perf_counter()\n",
    "    \n",
    "    return end - start\n",
    "\n",
    "def benchmark_gpu_n_ops(a, b, n_ops):\n",
    "    \"\"\"Benchmark GPU for n operations (data stays on GPU)\"\"\"\n",
    "    # Transfer to GPU once\n",
    "    d_a = cuda.to_device(a)\n",
    "    d_b = cuda.to_device(b)\n",
    "    d_c = cuda.device_array_like(a)\n",
    "    \n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (a.size + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    # Warmup\n",
    "    vector_add_gpu_kernel[blocks_per_grid, threads_per_block](d_a, d_b, d_c)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Measure (including final transfer back)\n",
    "    start = time_module.perf_counter()\n",
    "    for _ in range(n_ops):\n",
    "        vector_add_gpu_kernel[blocks_per_grid, threads_per_block](d_a, d_b, d_c)\n",
    "    cuda.synchronize()\n",
    "    result = d_c.copy_to_host()  # Transfer back\n",
    "    end = time_module.perf_counter()\n",
    "    \n",
    "    return end - start\n",
    "\n",
    "def check_cuda():\n",
    "    try:\n",
    "        cuda.select_device(0)\n",
    "        cuda.current_context()\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56d4b408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling Benchmark: CPU vs GPU (10,000,000 elements)\n",
      "\n",
      "┌──────────────┬────────────┬────────────┬──────────────┬──────────────┐\n",
      "│ # Operations │  CPU Time  │  GPU Time  │   Speedup    │    Winner    │\n",
      "├──────────────┼────────────┼────────────┼──────────────┼──────────────┤\n",
      "│            1 │    2.93 ms │    7.12 ms │  2.43x slower │     CPU      │\n",
      "│            2 │    6.68 ms │    6.97 ms │  1.04x slower │     CPU      │\n",
      "│            5 │   15.69 ms │    7.18 ms │  2.18x faster │     GPU      │\n",
      "│           10 │   32.47 ms │    6.93 ms │  4.69x faster │     GPU      │\n",
      "│           20 │   62.38 ms │    7.95 ms │  7.85x faster │     GPU      │\n",
      "│           50 │  152.07 ms │    9.55 ms │ 15.93x faster │     GPU      │\n",
      "│          100 │  319.62 ms │   12.99 ms │ 24.61x faster │     GPU      │\n",
      "│          200 │  631.49 ms │   19.58 ms │ 32.26x faster │     GPU      │\n",
      "│          500 │ 1536.38 ms │   39.60 ms │ 38.80x faster │     GPU      │\n",
      "└──────────────┴────────────┴────────────┴──────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "N = 10_000_000\n",
    "a = np.random.rand(N).astype(np.float32)\n",
    "b = np.random.rand(N).astype(np.float32)\n",
    "\n",
    "print(f\"\\nScaling Benchmark: CPU vs GPU ({N:,} elements)\\n\")\n",
    "\n",
    "cuda_available = check_cuda()\n",
    "\n",
    "if not cuda_available:\n",
    "    print(\"GPU not available - only showing CPU results\\n\")\n",
    "\n",
    "# Test different numbers of operations\n",
    "operation_counts = [1, 2, 5, 10, 20, 50, 100, 200, 500]\n",
    "\n",
    "print(\"┌──────────────┬────────────┬────────────┬──────────────┬──────────────┐\")\n",
    "print(\"│ # Operations │  CPU Time  │  GPU Time  │   Speedup    │    Winner    │\")\n",
    "print(\"├──────────────┼────────────┼────────────┼──────────────┼──────────────┤\")\n",
    "\n",
    "for n_ops in operation_counts:\n",
    "    # CPU benchmark\n",
    "    time_cpu = benchmark_cpu_n_ops(a, b, n_ops)\n",
    "    \n",
    "    if cuda_available:\n",
    "        # GPU benchmark\n",
    "        time_gpu = benchmark_gpu_n_ops(a, b, n_ops)\n",
    "        \n",
    "        # Calculate speedup\n",
    "        if time_gpu < time_cpu:\n",
    "            speedup = time_cpu / time_gpu\n",
    "            winner = \"GPU\"\n",
    "            speedup_str = f\"{speedup:>5.2f}x faster\"\n",
    "        else:\n",
    "            speedup = time_gpu / time_cpu\n",
    "            winner = \"CPU\"\n",
    "            speedup_str = f\"{speedup:>5.2f}x slower\"\n",
    "        \n",
    "        # Format times\n",
    "        cpu_time_str = f\"{time_cpu*1000:>7.2f} ms\"\n",
    "        gpu_time_str = f\"{time_gpu*1000:>7.2f} ms\"\n",
    "        \n",
    "        print(f\"│ {n_ops:>12} │ {cpu_time_str} │ {gpu_time_str} │ {speedup_str} │ {winner:^12} │\")\n",
    "    else:\n",
    "        cpu_time_str = f\"{time_cpu*1000:>7.2f} ms\"\n",
    "        print(f\"│ {n_ops:>12} │ {cpu_time_str} │     N/A    │      N/A     │     N/A      │\")\n",
    "\n",
    "print(\"└──────────────┴────────────┴────────────┴──────────────┴──────────────┘\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog-code-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
